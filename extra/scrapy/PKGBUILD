# Maintainer: Felix Yan <felixonmars@archlinux.org>
# Contributor: PyroDevil <p dot devil at gmail dot com>
# Contributor: Anibal Pacheco <apacheco.uy@gmail.com>

pkgname=scrapy
pkgver=2.13.4
pkgrel=3
pkgdesc="A fast high-level scraping and web crawling framework."
arch=('any')
license=('BSD-3-Clause')
url="https://scrapy.org"
depends=(
  'python'
  'python-cryptography'
  'python-cssselect'
  'python-defusedxml'
  'python-itemadapter'
  'python-itemloaders'
  'python-lxml'
  'python-packaging'
  'python-parsel'
  'python-protego'
  'python-pydispatcher'
  'python-pyopenssl'
  'python-queuelib'
  'python-service-identity'
  'python-setuptools'
  'python-tldextract'
  'python-twisted'
  'python-w3lib'
  'python-zope-interface'
)
makedepends=(
  'python-build'
  'python-hatchling'
  'python-installer'
  'python-wheel'
)
checkdepends=(
  'bpython'
  'ipython'
  'mitmproxy'
  'python-attrs'
  'python-botocore'
  'python-brotli'
  'python-h2'
  'python-markupsafe'
  'python-pyftpdlib'
  'python-pytest'
  'python-sybil'
  'python-testfixtures'
  'python-uvloop'
  'python-zstandard'
)
optdepends=(
  'bpython: for ncurses support in cmdline'
  'ipython: for enhanced support of the interactive scraping shell'
  'python-botocore: for various utils'
  'python-brotli: for HTTP compression using brotli'
  'python-h2: for HTTP2 support'
  'python-hpack: for HTTP2 streaming support'
  'python-zstandard: for HTTP compression using zstandard'
)
source=(
  "https://github.com/scrapy/scrapy/archive/$pkgver/$pkgname-$pkgver.tar.gz"
  "$pkgname-python-3.14.patch"
)
sha512sums=('28c337371ab19b3b32ad4f622ecd80601e7b2e4c502a4cd003da7bc5cf8e626d53a21703076c7227a1c5e6133b0cac35b26caaddd947751fcabfa0ddce4bafb3'
            '1c49919d930afc1cc9d74099d9207474b6ea93024b8b0c2aaf21b61855fb758ac05b10e0eeb924ce37da2e2eb25ab534fb43d1697f43fb2d9fd0ef4ba344eefe')
b2sums=('eb25a4afc99fd65665111d7cd13cdb88d92712430c12904415d9502c1b30bce5332f4db22d3b2fe5b610b35073d06634ce9f7768c8b9381c52261ef5073f3c30'
        'db10e489e4d09b49843b7ca5ffc3cb3fe20744a50fb029ab184946bf7a7ea8b581db8ac2baadbd7452e36c59affe6f87b3c910b0fca5c73b5f7596c18a734a72')

prepare() {
  cd $pkgname-$pkgver
  patch -Np1 < ../$pkgname-python-3.14.patch
}

build() {
  cd $pkgname-$pkgver
  python -m build --wheel --no-isolation
}

check() {
  local pytest_options=(
    -vv
    # integration tests are blocking and unnecessary
    --ignore tests/test_proxy_connect.py
    # TODO: raise upstream
    --deselect tests/test_crawl.py::CrawlTestCase::test_start_requests_laziness
    # Flaky, see: https://github.com/scrapy/scrapy/issues/7060
    --deselect tests/test_downloader_handlers.py::TestHttp11Proxy::test_download_with_proxy_https_timeout
    # Fails with AssertionError under Python 3.14, not sure why
    --deselect tests/test_crawler.py::TestCrawlerProcessSubprocess::test_asyncio_enabled_reactor_different_loop
    --deselect tests/test_pipeline_files.py::TestFilesPipeline::test_file_path
    --deselect tests/test_utils_asyncio.py::TestAsyncio::test_install_asyncio_reactor
  )
  local site_packages=$(python -c "import site; print(site.getsitepackages()[0])")

  cd $pkgname-$pkgver
  python -m installer --destdir=test_dir dist/*.whl
  export PYTHONPATH="$PWD/test_dir/$site_packages:$PYTHONPATH"
  pytest "${pytest_options[@]}" tests
}

package() {
  cd $pkgname-$pkgver

  python -m installer --destdir="$pkgdir" dist/*.whl

  # License and documentation
  install -Dm644 LICENSE -t "$pkgdir"/usr/share/licenses/$pkgname/
  install -Dm644 README.rst -t "$pkgdir"/usr/share/doc/$pkgname/
  install -Dm644 docs/intro/install.rst -t "$pkgdir"/usr/share/doc/$pkgname/

  # Shell completions
  install -Dm644 extras/scrapy_bash_completion \
    "$pkgdir"/usr/share/bash-completion/completions/scrapy
  install -Dm644 extras/scrapy_zsh_completion \
    "$pkgdir"/usr/share/zsh/site-functions/_scrapy
}
