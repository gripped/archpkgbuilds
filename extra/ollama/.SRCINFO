pkgbase = ollama
	pkgdesc = Create, run and share large language models (LLMs)
	pkgver = 0.1.36
	pkgrel = 1
	url = https://github.com/ollama/ollama
	arch = x86_64
	license = MIT
	makedepends = clblast
	makedepends = cmake
	makedepends = cuda
	makedepends = git
	makedepends = go
	makedepends = rocm-hip-sdk
	makedepends = rocm-opencl-sdk
	source = git+https://github.com/ollama/ollama#commit=92ca2cca954e590abe5eecb0a87fa13cec83b0e1
	source = llama.cpp::git+https://github.com/ggerganov/llama.cpp#commit=952d03dbead16e4dbdd1d3458486340673cc2465
	source = ollama.service
	source = sysusers.conf
	source = tmpfiles.d
	b2sums = dc8227c0d391a34863996b843b9c9e28f8f840fc082d80e70869fc14e0e8d2c24f07501b5d6fb6ab69e4f6d1cb4aad484af5b9ff4add29c0f9be0306b9c73905
	b2sums = f2e7fdf5eaf21f725fa868b4dd18ab602a4ec3f6bdd703bc674bf6537e9b57c7c87be945a2b6b774b6a7abfb6a36b2d15cf40ea67ba0c7958ced7eea46880702
	b2sums = 2bf4c2076b7841de266ec40da2e2cbb675dcbfebfa8aed8d4ede65435854cb43d39ea32bc9210cfc28a042382dd0094a153e351edfa5586eb7c6a0783f3bc517
	b2sums = 3aabf135c4f18e1ad745ae8800db782b25b15305dfeaaa031b4501408ab7e7d01f66e8ebb5be59fc813cfbff6788d08d2e48dcf24ecc480a40ec9db8dbce9fec
	b2sums = e8f2b19e2474f30a4f984b45787950012668bf0acb5ad1ebb25cd9776925ab4a6aa927f8131ed53e35b1c71b32c504c700fe5b5145ecd25c7a8284373bb951ed

pkgname = ollama
	pkgdesc = Create, run and share large language models (LLMs)

pkgname = ollama-cuda
	pkgdesc = Create, run and share large language models (LLMs) with CUDA
	optdepends = nvidia-utils: monitor GPU usage with nvidia-smi
	provides = ollama
	conflicts = ollama

pkgname = ollama-rocm
	pkgdesc = Create, run and share large language models (LLMs) with ROCm
	depends = hipblas
	provides = ollama
	conflicts = ollama
