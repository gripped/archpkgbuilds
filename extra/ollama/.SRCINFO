pkgbase = ollama
	pkgdesc = Create, run and share large language models (LLMs)
	pkgver = 0.3.3
	pkgrel = 1
	url = https://github.com/ollama/ollama
	arch = x86_64
	license = MIT
	makedepends = clblast
	makedepends = cmake
	makedepends = cuda
	makedepends = git
	makedepends = go
	makedepends = rocm-hip-sdk
	makedepends = rocm-opencl-sdk
	source = git+https://github.com/ollama/ollama#commit=ce1fb4447efc9958dcf279f7eb2ae6941bec1220
	source = llama.cpp::git+https://github.com/ggerganov/llama.cpp#commit=6eeaeba126ff701f3e8f79f246805b7023709972
	source = ollama.service
	source = sysusers.conf
	source = tmpfiles.d
	b2sums = d25741e97fb7f677e3bfe5d208cefb83e972ccbce2e4ea95acf6d911c783565149ae9b93d0b22dcb148d20b24c50cf6195144148b74cb11ef3b52b82a8a7acce
	b2sums = 84f5a77acc7bd29e734623490e5c6f85e43fea8618a0e383ded82d9285c66657a5383b5d987747f6bf6a956a33ad7a869c2fb2c18276d08fe224e4bb3a850cbb
	b2sums = 18a1468f5614f9737f6ff2e6c7dfb3dfc0ba82836a98e3f14f8e544e3aba8f74ef0a03c5376a0d0aa2e59e948701d7c639dda69477b051b732896021e753e32e
	b2sums = 3aabf135c4f18e1ad745ae8800db782b25b15305dfeaaa031b4501408ab7e7d01f66e8ebb5be59fc813cfbff6788d08d2e48dcf24ecc480a40ec9db8dbce9fec
	b2sums = e8f2b19e2474f30a4f984b45787950012668bf0acb5ad1ebb25cd9776925ab4a6aa927f8131ed53e35b1c71b32c504c700fe5b5145ecd25c7a8284373bb951ed

pkgname = ollama
	pkgdesc = Create, run and share large language models (LLMs)

pkgname = ollama-cuda
	pkgdesc = Create, run and share large language models (LLMs) with CUDA
	optdepends = nvidia-utils: monitor GPU usage with nvidia-smi
	provides = ollama
	conflicts = ollama

pkgname = ollama-rocm
	pkgdesc = Create, run and share large language models (LLMs) with ROCm
	depends = hipblas
	optdepends = rocm-smi-lib: monitor GPU usage with rocm-smi
	provides = ollama
	conflicts = ollama
