pkgbase = ollama
	pkgdesc = Create, run and share large language models (LLMs)
	pkgver = 0.3.11
	pkgrel = 1
	url = https://github.com/ollama/ollama
	install = msg.install
	arch = x86_64
	license = MIT
	makedepends = clblast
	makedepends = cmake
	makedepends = cuda
	makedepends = git
	makedepends = go
	makedepends = rocm-hip-sdk
	makedepends = rocm-opencl-sdk
	source = git+https://github.com/ollama/ollama#commit=504a410f02e01a2ec948a92e4579a28295184898
	source = llama.cpp::git+https://github.com/ggerganov/llama.cpp#commit=8962422b1c6f9b8b15f5aeaea42600bcc2d44177
	source = ollama.service
	source = sysusers.conf
	source = tmpfiles.d
	b2sums = 24f5a03a8a83110703d418df56a9a9194dcc649b5307dff8141ec7d8e7cfa0dc0f63da4521aa362ccb8f12e22ff86b363677fbb0f10ff608c2d04a577687b127
	b2sums = e568ac334cf07b69f98c4581f212f2e30bdebf1f285a37e4bb5c8ac31733df9a3c125e6d16b7f6bbe412cedb11d249a07ca9793a487e0ad34810cbb35cd32ee2
	b2sums = 031e0809a7f564de87017401c83956d43ac29bd0e988b250585af728b952a27d139b3cad0ab1e43750e2cd3b617287d3b81efc4a70ddd61709127f68bd15eabd
	b2sums = 3aabf135c4f18e1ad745ae8800db782b25b15305dfeaaa031b4501408ab7e7d01f66e8ebb5be59fc813cfbff6788d08d2e48dcf24ecc480a40ec9db8dbce9fec
	b2sums = e8f2b19e2474f30a4f984b45787950012668bf0acb5ad1ebb25cd9776925ab4a6aa927f8131ed53e35b1c71b32c504c700fe5b5145ecd25c7a8284373bb951ed

pkgname = ollama
	pkgdesc = Create, run and share large language models (LLMs)

pkgname = ollama-cuda
	pkgdesc = Create, run and share large language models (LLMs) with CUDA
	optdepends = nvidia-utils: monitor GPU usage with nvidia-smi
	provides = ollama
	conflicts = ollama

pkgname = ollama-rocm
	pkgdesc = Create, run and share large language models (LLMs) with ROCm
	depends = hipblas
	optdepends = rocm-smi-lib: monitor GPU usage with rocm-smi
	provides = ollama
	conflicts = ollama
